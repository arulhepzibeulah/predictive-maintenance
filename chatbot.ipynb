{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF5A3y0cNQNX"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import random\n",
        "import json\n",
        "from nltk.corpus import wordnet\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intents = {\n",
        "  \"intents\": [\n",
        "    {\n",
        "      \"tag\": \"MachineConditionCheck\",\n",
        "      \"patterns\": [\"How's the machine looking?\", \"Check machine condition\", \"Machine status?\"],\n",
        "      \"responses\": [\"The machine is currently in good condition.\" \"All performance metrics are normal.\"],\n",
        "      \"context_set\": \"\"\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"ProblemDetected\",\n",
        "      \"patterns\": [\"What should we do if there’s a problem?\",\"What if there’s an issue?\", \"How to handle machine problems?\"],\n",
        "      \"responses\": [\"If you see any issues, here's what to do:\"\n",
        "                   \"Unusual Noises: Check for loose parts or wear. Tighten or replace parts as needed.\"\n",
        "                   \"Temperature Spikes: Ensure cooling systems are working. Clean or repair cooling components if necessary.\"\n",
        "                   \"Vibration Issues: Inspect for misalignment or imbalance. Adjust or replace parts to correct the problem.\"\n",
        "                   \"Error Messages: Follow the error code instructions. Consult the manual or contact support if needed.`\"],\n",
        "      \"context_set\": \"\"\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"UnclearProblem\",\n",
        "      \"patterns\": [\"What if the problem isn’t clear?\", \"What if I can’t identify the issue?\", \"How to handle unclear problems?\"],\n",
        "      \"responses\": [\"If the issue isn’t obvious, perform a diagnostic check.\" \"Look at system logs for more details.\" \"If needed, escalate the issue to a senior technician.\"],\n",
        "      \"context_set\": \"\"\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"PreventFutureProblems\",\n",
        "      \"patterns\": [\"How can we prevent future problems?\", \"What to do to avoid issues in the future?\", \"How to prevent machine failures?\"],\n",
        "      \"responses\": [\"After fixing the issue, review the cause and update maintenance practices.\" \"Adjust schedules or improve monitoring based on new data.\"],\n",
        "      \"context_set\": \"\"\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"GeneralHelp\",\n",
        "      \"patterns\": [\"Thanks\", \"Thank you\", \"I need more help\"],\n",
        "      \"responses\": [\"You’re welcome! If you need more help, just ask.\"],\n",
        "      \"context_set\": \"\"\n",
        "    }\n",
        "\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "4Y4NN_3bNwpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def synonym_replacement(tokens, limit):\n",
        "    augmented_sentences = []\n",
        "    for i in range(len(tokens)):\n",
        "        synonyms = []\n",
        "        for syn in wordnet.synsets(tokens[i]):\n",
        "            for lemma in syn.lemmas():\n",
        "                synonyms.append(lemma.name())\n",
        "        if len(synonyms) > 0:\n",
        "            num_augmentations = min(limit, len(synonyms))\n",
        "            sampled_synonyms = random.sample(synonyms, num_augmentations)\n",
        "            for synonym in sampled_synonyms:\n",
        "                augmented_tokens = tokens[:i] + [synonym] + tokens[i+1:]\n",
        "                augmented_sentences.append(' '.join(augmented_tokens))\n",
        "    return augmented_sentences"
      ],
      "metadata": {
        "id": "HXIU41LuN1Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk numpy pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0X8iFeOPTOL",
        "outputId": "fd58b48b-cff0-4268-dca6-b2700da89b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Now you can proceed with your script\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaxEfGJUPV4k",
        "outputId": "c6875e5a-20c4-400a-e0c8-092d44523958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = []\n",
        "labels = []\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "limit_per_tag = 40\n",
        "\n",
        "for intent in intents['intents']:\n",
        "    augmented_sentences_per_tag = 0\n",
        "    for example in intent['patterns']:\n",
        "        tokens = nltk.word_tokenize(example.lower())\n",
        "        filtered_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stopwords and token.isalpha()]\n",
        "        if filtered_tokens:\n",
        "            text_data.append(' '.join(filtered_tokens))\n",
        "            labels.append(intent['tag'])\n",
        "\n",
        "            augmented_sentences = synonym_replacement(filtered_tokens, limit_per_tag - augmented_sentences_per_tag)\n",
        "            for augmented_sentence in augmented_sentences:\n",
        "                text_data.append(augmented_sentence)\n",
        "                labels.append(intent['tag'])\n",
        "                augmented_sentences_per_tag += 1\n",
        "                if augmented_sentences_per_tag >= limit_per_tag:\n",
        "                    break\n",
        "\n",
        "print(len(text_data))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4TBkdzdPk86",
        "outputId": "27961eca-3a6e-4eaf-a3de-9dee59569910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215\n",
            "215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(text_data)\n",
        "y = labels"
      ],
      "metadata": {
        "id": "2H1P_5GnQIsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XDXlRHKfaAGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OV9YxpSyq_nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NlVhDhe6a7oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_model(X, y, test_size=0.2):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=100)\n",
        "\n",
        "\n",
        "    models = [\n",
        "        ('Logistic Regression', LogisticRegression(), {\n",
        "            'penalty': ['l2'],\n",
        "            'C': [0.1, 1.0, 10.0],\n",
        "            'solver': ['liblinear'],\n",
        "            'max_iter': [100, 1000, 10000]\n",
        "        }),\n",
        "        ('Multinomial Naive Bayes', MultinomialNB(), {'alpha': [0.1, 0.5, 1.0]}),\n",
        "        ('Linear SVC', LinearSVC(), {\n",
        "            'penalty': ['l2'],\n",
        "            'loss': ['hinge', 'squared_hinge'],\n",
        "            'C': [0.1, 1, 10],\n",
        "            'max_iter': [100, 1000, 10000]\n",
        "        }),\n",
        "        ('Decision Tree', DecisionTreeClassifier(), {\n",
        "            'max_depth': [5, 10, 20, None],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4],\n",
        "            'criterion': ['gini', 'entropy']\n",
        "        }),\n",
        "        ('Random Forest', RandomForestClassifier(), {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'max_depth': [10, 20, None],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4]\n",
        "        })\n",
        "    ]\n",
        "\n",
        "    for name, model, param_grid in models:\n",
        "        grid = GridSearchCV(model, param_grid, cv=3, n_jobs=-1)\n",
        "        grid.fit(X_train, y_train)\n",
        "        y_pred = grid.predict(X_test)\n",
        "        score = accuracy_score(y_test, y_pred)\n",
        "        print(f'{name}: {score:.4f} (best parameters: {grid.best_params_})')\n",
        "\n",
        "    best_model = max(models, key=lambda x: GridSearchCV(x[1], x[2], cv=3, n_jobs=-1).fit(X_train, y_train).score(X_test, y_test))\n",
        "    print(f'\\nBest model: {best_model[0]}')\n",
        "\n",
        "\n",
        "    best_model[1].fit(X, y)\n",
        "\n",
        "    return best_model[1]"
      ],
      "metadata": {
        "id": "GcWYZkP_QKNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = find_best_model(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9n6tN3WUxij",
        "outputId": "83320045-bc99-4e3f-8781-728362812c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression: 0.8837 (best parameters: {'C': 1.0, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'})\n",
            "Multinomial Naive Bayes: 0.8837 (best parameters: {'alpha': 0.1})\n",
            "Linear SVC: 0.8837 (best parameters: {'C': 0.1, 'loss': 'squared_hinge', 'max_iter': 100, 'penalty': 'l2'})\n",
            "Decision Tree: 0.8837 (best parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5})\n",
            "Random Forest: 0.9070 (best parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100})\n",
            "\n",
            "Best model: Random Forest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(user_input):\n",
        "    input_text = vectorizer.transform([user_input])\n",
        "    predicted_intent = best_model.predict(input_text)[0]\n",
        "\n",
        "    for intent in intents['intents']:\n",
        "        if intent['tag'] == predicted_intent:\n",
        "            response = random.choice(intent['responses'])\n",
        "            break\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "hltYToUtWycz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Hello! I am a chatbot. How can I help you today? Type \"quit\" to exit.')\n",
        "while True:\n",
        "    user_input = input('> ')\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "    response = chatbot_response(user_input)\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR5Xj6VAW3LA",
        "outputId": "6b52e63a-723e-4e46-8a58-f79371a97802"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I am a chatbot. How can I help you today? Type \"quit\" to exit.\n",
            "> quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQVshYRra9IO",
        "outputId": "745ef674-eb1a-44ed-f9c5-122f5c4f0fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Your data\n",
        "data = {\"key\": \"value\"}\n",
        "\n",
        "# Save to a .pkl file\n",
        "with open(\"data.pkl\", \"wb\") as f:\n",
        "    pickle.dump(data, f)\n",
        "\n",
        "# Check if the file exists in the working directory\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZy1ZAqcd6v0",
        "outputId": "9fe2d866-c921-4405-908f-e64ff04128af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.pkl  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the first file\n",
        "files.download('best_model.pkl')\n",
        "\n",
        "# If you have two separate files, give the second one a unique name\n",
        "# Download the second file (if it exists with a different name or location)\n",
        "files.download('best_model_2.pkl')  # Change the name as per your file structure\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "yABiwkand6yQ",
        "outputId": "535e6e13-a397-4fad-b240-ff07ab2e7bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: best_model.pkl",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7d52640b5835>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Download the first file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# If you have two separate files, give the second one a unique name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: best_model.pkl"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Assuming 'model' is your trained model\n",
        "joblib.dump(model, 'best_model.joblib')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "REprQTnSd603",
        "outputId": "18b57279-2728-4bb9-dd60-e652ac911152"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c14ff3ae3af2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Assuming 'model' is your trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best_model.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Assuming 'model' is your trained model\n",
        "joblib.dump( best_model,'best_model.joblib')\n"
      ],
      "metadata": {
        "id": "7yHrfethd63J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "013430fe-01bc-47f3-e87b-0732d52a30bf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['best_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Assuming 'model' is your trained model\n",
        "joblib.dump( vectorizer,'vectorizer.joblib')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liroP_L6rA_Q",
        "outputId": "0442a5de-d481-4391-b021-0583d8f270dc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vectorizer.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load the saved model\n",
        "model = joblib.load('best_model.joblib')\n",
        "print(model.get_params())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfatM5byri3m",
        "outputId": "a6449db9-b27b-4b5c-ad2d-fdd3b6f538d1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have input data X\n",
        "predictions = model.predict(X)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFYHVrvfri7G",
        "outputId": "21da1e88-e088-4fde-8e6f-ea8c459721b2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'MachineConditionCheck' 'MachineConditionCheck'\n",
            " 'MachineConditionCheck' 'ProblemDetected' 'ProblemDetected'\n",
            " 'ProblemDetected' 'ProblemDetected' 'ProblemDetected' 'ProblemDetected'\n",
            " 'ProblemDetected' 'ProblemDetected' 'ProblemDetected' 'ProblemDetected'\n",
            " 'ProblemDetected' 'ProblemDetected' 'ProblemDetected' 'ProblemDetected'\n",
            " 'ProblemDetected' 'ProblemDetected' 'ProblemDetected' 'ProblemDetected'\n",
            " 'ProblemDetected' 'ProblemDetected' 'ProblemDetected' 'ProblemDetected'\n",
            " 'ProblemDetected' 'ProblemDetected' 'ProblemDetected' 'ProblemDetected'\n",
            " 'ProblemDetected' 'ProblemDetected' 'ProblemDetected' 'ProblemDetected'\n",
            " 'ProblemDetected' 'ProblemDetected' 'ProblemDetected' 'ProblemDetected'\n",
            " 'ProblemDetected' 'ProblemDetected' 'ProblemDetected' 'ProblemDetected'\n",
            " 'ProblemDetected' 'ProblemDetected' 'ProblemDetected' 'ProblemDetected'\n",
            " 'ProblemDetected' 'UnclearProblem' 'UnclearProblem' 'UnclearProblem'\n",
            " 'UnclearProblem' 'UnclearProblem' 'UnclearProblem' 'UnclearProblem'\n",
            " 'UnclearProblem' 'UnclearProblem' 'UnclearProblem' 'UnclearProblem'\n",
            " 'UnclearProblem' 'UnclearProblem' 'UnclearProblem' 'UnclearProblem'\n",
            " 'UnclearProblem' 'UnclearProblem' 'UnclearProblem' 'UnclearProblem'\n",
            " 'UnclearProblem' 'UnclearProblem' 'UnclearProblem' 'UnclearProblem'\n",
            " 'UnclearProblem' 'UnclearProblem' 'UnclearProblem' 'UnclearProblem'\n",
            " 'UnclearProblem' 'UnclearProblem' 'UnclearProblem' 'UnclearProblem'\n",
            " 'UnclearProblem' 'UnclearProblem' 'UnclearProblem' 'UnclearProblem'\n",
            " 'UnclearProblem' 'UnclearProblem' 'UnclearProblem' 'UnclearProblem'\n",
            " 'UnclearProblem' 'UnclearProblem' 'UnclearProblem' 'UnclearProblem'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'PreventFutureProblems' 'PreventFutureProblems'\n",
            " 'PreventFutureProblems' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp'\n",
            " 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp'\n",
            " 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp'\n",
            " 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp'\n",
            " 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp'\n",
            " 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp'\n",
            " 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp'\n",
            " 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp'\n",
            " 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp' 'GeneralHelp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(model))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jFxB7xarjI1",
        "outputId": "4ec4eb6b-7309-4787-d266-68516308efe6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fdhh49yVrjMO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}